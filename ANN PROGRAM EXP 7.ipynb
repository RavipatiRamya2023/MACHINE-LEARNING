{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMm9H/jkDg4T+WQSPwV0KBV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jHkPnQHgYefb","executionInfo":{"status":"ok","timestamp":1743243277590,"user_tz":-330,"elapsed":357,"user":{"displayName":"ramya ravipati","userId":"11356452001354288215"}},"outputId":"422b1ba1-0b1d-4a10-c92b-2e14e370782c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0: Loss = 0.409059\n","Epoch 500: Loss = 0.000718\n","Epoch 1000: Loss = 0.000338\n","Epoch 1500: Loss = 0.000218\n","Epoch 2000: Loss = 0.000160\n","Epoch 2500: Loss = 0.000126\n","Epoch 3000: Loss = 0.000104\n","Epoch 3500: Loss = 0.000088\n","Epoch 4000: Loss = 0.000077\n","Epoch 4500: Loss = 0.000068\n","Final Accuracy: 100.00%\n"]}],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder, StandardScaler\n","\n","# Activation functions and their derivatives\n","def sigmoid(x):\n","    return 1 / (1 + np.exp(-x))\n","\n","def sigmoid_derivative(x):\n","    return x * (1 - x)\n","\n","# Load dataset\n","file_path = \"/iris(1).csv\"\n","df = pd.read_csv(file_path)\n","\n","# Encode categorical target\n","label_encoder = LabelEncoder()\n","df['species'] = label_encoder.fit_transform(df['species'])\n","\n","# Split features and target\n","X = df.iloc[:, :-1].values  # Feature columns\n","y = df.iloc[:, -1].values   # Target column\n","\n","# One-hot encode target\n","y = np.eye(len(np.unique(y)))[y]\n","\n","# Normalize input features\n","scaler = StandardScaler()\n","X = scaler.fit_transform(X)\n","\n","# Split dataset\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Neural Network parameters\n","input_size = X.shape[1]   # Number of input neurons\n","hidden_size = 5           # Number of hidden neurons\n","output_size = y.shape[1]  # Number of output neurons\n","learning_rate = 0.1       # Learning rate\n","epochs = 5000             # Number of training iterations\n","\n","# Initialize weights and biases\n","np.random.seed(42)\n","weights_input_hidden = np.random.uniform(-1, 1, (input_size, hidden_size))\n","weights_hidden_output = np.random.uniform(-1, 1, (hidden_size, output_size))\n","bias_hidden = np.zeros((1, hidden_size))\n","bias_output = np.zeros((1, output_size))\n","\n","# Training loop\n","for epoch in range(epochs):\n","    # Forward propagation\n","    hidden_layer_input = np.dot(X_train, weights_input_hidden) + bias_hidden\n","    hidden_layer_output = sigmoid(hidden_layer_input)\n","    output_layer_input = np.dot(hidden_layer_output, weights_hidden_output) + bias_output\n","    output_layer_output = sigmoid(output_layer_input)\n","\n","    # Compute loss (Mean Squared Error)\n","    error = y_train - output_layer_output\n","    loss = np.mean(error ** 2)\n","\n","    # Backpropagation\n","    output_gradient = error * sigmoid_derivative(output_layer_output)\n","    hidden_gradient = np.dot(output_gradient, weights_hidden_output.T) * sigmoid_derivative(hidden_layer_output)\n","\n","    # Update weights and biases\n","    weights_hidden_output += np.dot(hidden_layer_output.T, output_gradient) * learning_rate\n","    bias_output += np.sum(output_gradient, axis=0, keepdims=True) * learning_rate\n","    weights_input_hidden += np.dot(X_train.T, hidden_gradient) * learning_rate\n","    bias_hidden += np.sum(hidden_gradient, axis=0, keepdims=True) * learning_rate\n","\n","    # Print loss every 500 epochs\n","    if epoch % 500 == 0:\n","        print(f\"Epoch {epoch}: Loss = {loss:.6f}\")\n","\n","# Testing\n","hidden_layer_input = np.dot(X_test, weights_input_hidden) + bias_hidden\n","hidden_layer_output = sigmoid(hidden_layer_input)\n","output_layer_input = np.dot(hidden_layer_output, weights_hidden_output) + bias_output\n","output_layer_output = sigmoid(output_layer_input)\n","\n","y_pred = np.argmax(output_layer_output, axis=1)\n","y_true = np.argmax(y_test, axis=1)\n","accuracy = np.mean(y_pred == y_true) * 100\n","\n","print(f\"Final Accuracy: {accuracy:.2f}%\")\n"]}]}